{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import ipyplot\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.optim import Adam \n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as mpl_color_map\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style()\n",
    "model_path = \"vgg_trained2.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the following three cells contain code from the repository pytorch-cnn-visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#misc_functions.py\n",
    "\n",
    "\"\"\"\n",
    "Created on Thu Oct 21 11:09:09 2017\n",
    "\n",
    "@author: Utku Ozbulak - github.com/utkuozbulak\n",
    "\"\"\"\n",
    "\n",
    "def convert_to_grayscale(im_as_arr):\n",
    "    \"\"\"\n",
    "        Converts 3d image to grayscale\n",
    "\n",
    "    Args:\n",
    "        im_as_arr (numpy arr): RGB image with shape (D,W,H)\n",
    "\n",
    "    returns:\n",
    "        grayscale_im (numpy_arr): Grayscale image with shape (1,W,D)\n",
    "    \"\"\"\n",
    "    grayscale_im = np.sum(np.abs(im_as_arr), axis=0)\n",
    "    im_max = np.percentile(grayscale_im, 99)\n",
    "    im_min = np.min(grayscale_im)\n",
    "    grayscale_im = (np.clip((grayscale_im - im_min) / (im_max - im_min), 0, 1))\n",
    "    grayscale_im = np.expand_dims(grayscale_im, axis=0)\n",
    "    return grayscale_im\n",
    "\n",
    "\n",
    "def save_gradient_images(gradient, file_name):\n",
    "    \"\"\"\n",
    "        Exports the original gradient image\n",
    "\n",
    "    Args:\n",
    "        gradient (np arr): Numpy array of the gradient with shape (3, 224, 224)\n",
    "        file_name (str): File name to be exported\n",
    "    \"\"\"\n",
    "    if not os.path.exists('../results'):\n",
    "        os.makedirs('../results')\n",
    "    # Normalize\n",
    "    gradient = gradient - gradient.min()\n",
    "    gradient /= gradient.max()\n",
    "    # Save image\n",
    "    path_to_file = os.path.join('../results', file_name + '.png')\n",
    "    save_image(gradient, path_to_file)\n",
    "\n",
    "\n",
    "def save_class_activation_images(org_img, activation_map, file_name):\n",
    "    \"\"\"\n",
    "        Saves cam activation map and activation map on the original image\n",
    "\n",
    "    Args:\n",
    "        org_img (PIL img): Original image\n",
    "        activation_map (numpy arr): Activation map (grayscale) 0-255\n",
    "        file_name (str): File name of the exported image\n",
    "    \"\"\"\n",
    "    if not os.path.exists('../results'):\n",
    "        os.makedirs('../results')\n",
    "    # Grayscale activation map\n",
    "    heatmap, heatmap_on_image = apply_colormap_on_image(org_img, activation_map, 'hsv')\n",
    "    # Save colored heatmap\n",
    "    path_to_file = os.path.join('../results', file_name+'_Cam_Heatmap.png')\n",
    "    save_image(heatmap, path_to_file)\n",
    "    # Save heatmap on iamge\n",
    "    path_to_file = os.path.join('../results', file_name+'_Cam_On_Image.png')\n",
    "    save_image(heatmap_on_image, path_to_file)\n",
    "    # SAve grayscale heatmap\n",
    "    path_to_file = os.path.join('../results', file_name+'_Cam_Grayscale.png')\n",
    "    save_image(activation_map, path_to_file)\n",
    "\n",
    "\n",
    "def apply_colormap_on_image(org_im, activation, colormap_name):\n",
    "    \"\"\"\n",
    "        Apply heatmap on image\n",
    "    Args:\n",
    "        org_img (PIL img): Original image\n",
    "        activation_map (numpy arr): Activation map (grayscale) 0-255\n",
    "        colormap_name (str): Name of the colormap\n",
    "    \"\"\"\n",
    "    # Get colormap\n",
    "    color_map = mpl_color_map.get_cmap(colormap_name)\n",
    "    no_trans_heatmap = color_map(activation)\n",
    "    # Change alpha channel in colormap to make sure original image is displayed\n",
    "    heatmap = copy.copy(no_trans_heatmap)\n",
    "    heatmap[:, :, 3] = 0.4\n",
    "    heatmap = Image.fromarray((heatmap*255).astype(np.uint8))\n",
    "    no_trans_heatmap = Image.fromarray((no_trans_heatmap*255).astype(np.uint8))\n",
    "\n",
    "    # Apply heatmap on image\n",
    "    heatmap_on_image = Image.new(\"RGBA\", org_im.size)\n",
    "    heatmap_on_image = Image.alpha_composite(heatmap_on_image, org_im.convert('RGBA'))\n",
    "    heatmap_on_image = Image.alpha_composite(heatmap_on_image, heatmap)\n",
    "    return no_trans_heatmap, heatmap_on_image\n",
    "\n",
    "\n",
    "def apply_heatmap(R, sx, sy):\n",
    "    \"\"\"\n",
    "        Heatmap code stolen from https://git.tu-berlin.de/gmontavon/lrp-tutorial\n",
    "\n",
    "        This is (so far) only used for LRP\n",
    "    \"\"\"\n",
    "    b = 10*((np.abs(R)**3.0).mean()**(1.0/3))\n",
    "    my_cmap = plt.cm.seismic(np.arange(plt.cm.seismic.N))\n",
    "    my_cmap[:, 0:3] *= 0.85\n",
    "    my_cmap = ListedColormap(my_cmap)\n",
    "    plt.figure(figsize=(sx, sy))\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.axis('off')\n",
    "    heatmap = plt.imshow(R, cmap=my_cmap, vmin=-b, vmax=b, interpolation='nearest')\n",
    "    return heatmap\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def format_np_output(np_arr):\n",
    "    \"\"\"\n",
    "        This is a (kind of) bandaid fix to streamline saving procedure.\n",
    "        It converts all the outputs to the same format which is 3xWxH\n",
    "        with using sucecssive if clauses.\n",
    "    Args:\n",
    "        im_as_arr (Numpy array): Matrix of shape 1xWxH or WxH or 3xWxH\n",
    "    \"\"\"\n",
    "    # Phase/Case 1: The np arr only has 2 dimensions\n",
    "    # Result: Add a dimension at the beginning\n",
    "    if len(np_arr.shape) == 2:\n",
    "        np_arr = np.expand_dims(np_arr, axis=0)\n",
    "    # Phase/Case 2: Np arr has only 1 channel (assuming first dim is channel)\n",
    "    # Result: Repeat first channel and convert 1xWxH to 3xWxH\n",
    "    if np_arr.shape[0] == 1:\n",
    "        np_arr = np.repeat(np_arr, 3, axis=0)\n",
    "    # Phase/Case 3: Np arr is of shape 3xWxH\n",
    "    # Result: Convert it to WxHx3 in order to make it saveable by PIL\n",
    "    if np_arr.shape[0] == 3:\n",
    "        np_arr = np_arr.transpose(1, 2, 0)\n",
    "    # Phase/Case 4: NP arr is normalized between 0-1\n",
    "    # Result: Multiply with 255 and change type to make it saveable by PIL\n",
    "    if np.max(np_arr) <= 1:\n",
    "        np_arr = (np_arr*255).astype(np.uint8)\n",
    "    return np_arr\n",
    "\n",
    "\n",
    "def save_image(im, path):\n",
    "    \"\"\"\n",
    "        Saves a numpy matrix or PIL image as an image\n",
    "    Args:\n",
    "        im_as_arr (Numpy array): Matrix of shape DxWxH\n",
    "        path (str): Path to the image\n",
    "    \"\"\"\n",
    "    if isinstance(im, (np.ndarray, np.generic)):\n",
    "        im = format_np_output(im)\n",
    "        im = Image.fromarray(im)\n",
    "    im.save(path)\n",
    "\n",
    "\n",
    "def preprocess_image(pil_im, resize_im=True):\n",
    "    \"\"\"\n",
    "        Processes image for CNNs\n",
    "\n",
    "    Args:\n",
    "        PIL_img (PIL_img): PIL Image or numpy array to process\n",
    "        resize_im (bool): Resize to 224 or not\n",
    "    returns:\n",
    "        im_as_var (torch variable): Variable that contains processed float tensor\n",
    "    \"\"\"\n",
    "    # Mean and std list for channels (Imagenet)\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # Ensure or transform incoming image to PIL image\n",
    "    if type(pil_im) != Image.Image:\n",
    "        try:\n",
    "            pil_im = Image.fromarray(pil_im)\n",
    "        except Exception as e:\n",
    "            print(\"could not transform PIL_img to a PIL Image object. Please check input.\")\n",
    "\n",
    "    # Resize image\n",
    "    if resize_im:\n",
    "        pil_im = pil_im.resize((224, 224), Image.ANTIALIAS)\n",
    "\n",
    "    im_as_arr = np.float32(pil_im)\n",
    "    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n",
    "    # Normalize the channels\n",
    "    for channel, _ in enumerate(im_as_arr):\n",
    "        im_as_arr[channel] /= 255\n",
    "        im_as_arr[channel] -= mean[channel]\n",
    "        im_as_arr[channel] /= std[channel]\n",
    "    # Convert to float tensor\n",
    "    im_as_ten = torch.from_numpy(im_as_arr).float()\n",
    "    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n",
    "    im_as_ten.unsqueeze_(0)\n",
    "    # Convert to Pytorch variable\n",
    "    im_as_var = Variable(im_as_ten, requires_grad=True)\n",
    "    return im_as_var\n",
    "\n",
    "\n",
    "def recreate_image(im_as_var):\n",
    "    \"\"\"\n",
    "        Recreates images from a torch variable, sort of reverse preprocessing\n",
    "    Args:\n",
    "        im_as_var (torch variable): Image to recreate\n",
    "    returns:\n",
    "        recreated_im (numpy arr): Recreated image in array\n",
    "    \"\"\"\n",
    "    reverse_mean = [-0.485, -0.456, -0.406]\n",
    "    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
    "    recreated_im = copy.copy(im_as_var.data.numpy()[0])\n",
    "    for c in range(3):\n",
    "        recreated_im[c] /= reverse_std[c]\n",
    "        recreated_im[c] -= reverse_mean[c]\n",
    "    recreated_im[recreated_im > 1] = 1\n",
    "    recreated_im[recreated_im < 0] = 0\n",
    "    recreated_im = np.round(recreated_im * 255)\n",
    "\n",
    "    recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)\n",
    "    return recreated_im\n",
    "\n",
    "\n",
    "def get_positive_negative_saliency(gradient):\n",
    "    \"\"\"\n",
    "        Generates positive and negative saliency maps based on the gradient\n",
    "    Args:\n",
    "        gradient (numpy arr): Gradient of the operation to visualize\n",
    "\n",
    "    returns:\n",
    "        pos_saliency ( )\n",
    "    \"\"\"\n",
    "    pos_saliency = (np.maximum(0, gradient) / gradient.max())\n",
    "    neg_saliency = (np.maximum(0, -gradient) / -gradient.min())\n",
    "    return pos_saliency, neg_saliency\n",
    "\n",
    "\n",
    "def get_example_params(example_index):\n",
    "    \"\"\"\n",
    "        Gets used variables for almost all visualizations, like the image, model etc.\n",
    "\n",
    "    Args:\n",
    "        example_index (int): Image id to use from examples\n",
    "\n",
    "    returns:\n",
    "        original_image (numpy arr): Original image read from the file\n",
    "        prep_img (numpy_arr): Processed image\n",
    "        target_class (int): Target class for the image\n",
    "        file_name_to_export (string): File name to export the visualizations\n",
    "        pretrained_model(Pytorch model): Model to use for the operations\n",
    "    \"\"\"\n",
    "    # Pick one of the examples\n",
    "    example_list = (('../input_images/snake.png', 56),\n",
    "                    ('../input_images/cat_dog.png', 243),\n",
    "                    ('../input_images/spider.png', 72))\n",
    "    img_path = example_list[example_index][0]\n",
    "    target_class = example_list[example_index][1]\n",
    "    file_name_to_export = img_path[img_path.rfind('/')+1:img_path.rfind('.')]\n",
    "    # Read image\n",
    "    original_image = Image.open(img_path).convert('RGB')\n",
    "    # Process image\n",
    "    prep_img = preprocess_image(original_image)\n",
    "    # Define model\n",
    "    pretrained_model = models.alexnet(pretrained=True)\n",
    "    return (original_image,\n",
    "            prep_img,\n",
    "            target_class,\n",
    "            file_name_to_export,\n",
    "            pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vanilla_backprop.py\n",
    "\n",
    "\"\"\"\n",
    "Created on Thu Oct 26 11:19:58 2017\n",
    "\n",
    "@author: Utku Ozbulak - github.com/utkuozbulak\n",
    "\"\"\"\n",
    "class VanillaBackprop():\n",
    "    \"\"\"\n",
    "        Produces gradients generated with vanilla back propagation from the image\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.gradients = None\n",
    "        # Put model in evaluation mode\n",
    "        self.model.eval()\n",
    "        # Hook the first layer to get the gradient\n",
    "        self.hook_layers()\n",
    "\n",
    "    def hook_layers(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            self.gradients = grad_in[0]\n",
    "\n",
    "        # Register hook to the first layer\n",
    "        first_layer = list(self.model.features._modules.items())[0][1]\n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "    def generate_gradients(self, input_image, target_class):\n",
    "        # Forward\n",
    "        model_output = self.model(input_image)\n",
    "        # Zero grads\n",
    "        self.model.zero_grad()\n",
    "        # Target for backprop\n",
    "        one_hot_output = torch.FloatTensor(1, model_output.size()[-1]).zero_()\n",
    "        one_hot_output[0][target_class] = 1\n",
    "        # Backward pass\n",
    "        model_output.backward(gradient=one_hot_output)\n",
    "        # Convert Pytorch variable to numpy array\n",
    "        # [0] to get rid of the first channel (1,3,224,224)\n",
    "        gradients_as_arr = self.gradients.data.numpy()[0]\n",
    "        gradients_as_arr -= gradients_as_arr.min()\n",
    "        gradients_as_arr /= gradients_as_arr.max()\n",
    "        return gradients_as_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn_layer_visualization.py\n",
    "\n",
    "class CNNLayerVisualization():\n",
    "    \"\"\"\n",
    "        Produces an image that minimizes the loss of a convolution\n",
    "        operation for a specific layer and filter\n",
    "    \"\"\"\n",
    "    def __init__(self, model, selected_layer, selected_filter, iter=50):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.selected_layer = selected_layer\n",
    "        self.selected_filter = selected_filter\n",
    "        self.conv_output = 0\n",
    "        self.iter = iter\n",
    "        # Create the folder to export images if not exists\n",
    "        if not os.path.exists('../generated'):\n",
    "            os.makedirs('../generated')\n",
    "\n",
    "    def hook_layer(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            # Gets the conv output of the selected filter (from selected layer)\n",
    "            self.conv_output = grad_out[0, self.selected_filter]\n",
    "        # Hook the selected layer\n",
    "        self.model[self.selected_layer].register_forward_hook(hook_function)\n",
    "\n",
    "    def visualise_layer_with_hooks(self, image):\n",
    "        # Hook the selected layer\n",
    "        self.hook_layer()\n",
    "        self.created_image = None\n",
    "        # Process image and return variable\n",
    "        processed_image = preprocess_image(image, True)\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "\n",
    "        visualisations = []\n",
    "\n",
    "        for i in range(1, self.iter+1):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                # x is not used after this point because it is only needed to trigger\n",
    "                # the forward hook function\n",
    "                x = layer(x)\n",
    "                # Only need to forward until the selected layer is reached\n",
    "                if index == self.selected_layer:\n",
    "                    # (forward hook function triggered)\n",
    "                    break\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "            #print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image)\n",
    "            # Save image\n",
    "            if i % 5 == 0: #save images after this interval\n",
    "                visualisations.append(self.created_image)\n",
    "        return visualisations\n",
    "\n",
    "    def visualise_layer_without_hooks(self):\n",
    "        # Process image and return variable\n",
    "        # Generate a random image\n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "        # Process image and return variable\n",
    "        processed_image = preprocess_image(random_image, False)\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                x = layer(x)\n",
    "                if index == self.selected_layer:\n",
    "                    # Only need to forward until the selected layer is reached\n",
    "                    # Now, x is the output of the selected layer\n",
    "                    break\n",
    "            # Here, we get the specific filter from the output of the convolution operation\n",
    "            # x is a tensor of shape 1x512x28x28.(For layer 17)\n",
    "            # So there are 512 unique filter outputs\n",
    "            # Following line selects a filter from 512 filters so self.conv_output will become\n",
    "            # a tensor of shape 28x28\n",
    "            self.conv_output = x[0, self.selected_filter]\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image)\n",
    "            # Save image\n",
    "            if i % 5 == 0:\n",
    "                im_path = '../generated/layer_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the custom trained VGG model\n",
    "model = models.vgg16(pretrained=True)\n",
    "#change last layer to have 10 outputs\n",
    "model.classifier[6] = nn.Linear(4096, 10)\n",
    "device = torch.device('cpu')\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Question 3: Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_cnn_layer = CNNLayerVisualization(model.features, selected_layer=24, selected_filter=1, iter=40) #visualise filter 1 in layer 24\n",
    "\n",
    "filenames = os.listdir(\"./cat_images/\")\n",
    "for filename in filenames:\n",
    "    image = Image.open(\"./cat_images/\" + filename).convert('RGB')\n",
    "    visualisations = visualise_cnn_layer.visualise_layer_with_hooks(np.asarray(image))\n",
    "    print(\"visualising \", filename)\n",
    "    #use ipyplot to display images\n",
    "    ipyplot.plot_images(visualisations, max_images=40//5, labels=[\"iteration \" + str(i*5) for i in range(1,9)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Question 3: Part 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "backpropagation = VanillaBackprop(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gradients = []\n",
    "target_class = 2 #any target class\n",
    "filenames = os.listdir(\"./cat_images/\")\n",
    "for filename in filenames:\n",
    "    image = Image.open(\"./cat_images/\" + filename).convert('RGB')\n",
    "    image = preprocess_image(image)\n",
    "    vanilla_grads = backpropagation.generate_gradients(image, target_class)\n",
    "    # Convert to grayscale\n",
    "    grayscale_vanilla_grads = convert_to_grayscale(vanilla_grads)\n",
    "    img = Image.fromarray(format_np_output(grayscale_vanilla_grads))\n",
    "    output_gradients.append((filename, img))\n",
    "ipyplot.plot_images([gradient[1] for gradient in output_gradients], max_images=len(output_gradients), labels=[gradient[0] for gradient in output_gradients])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Question 3: Part 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "cnn_random_visualization = CNNLayerVisualization(model.features, 1, 5, 30) #start with any layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 done\n",
      "Layer 1 done\n",
      "Layer 2 done\n",
      "Layer 3 done\n",
      "Layer 4 done\n",
      "Layer 5 done\n",
      "Layer 6 done\n",
      "Layer 7 done\n",
      "Layer 8 done\n",
      "Layer 9 done\n",
      "Layer 10 done\n",
      "Layer 11 done\n",
      "Layer 12 done\n",
      "Layer 13 done\n",
      "Layer 14 done\n",
      "Layer 15 done\n",
      "Layer 16 done\n",
      "Layer 17 done\n",
      "Layer 18 done\n",
      "Layer 19 done\n",
      "Layer 20 done\n",
      "Layer 21 done\n",
      "Layer 22 done\n",
      "Layer 23 done\n",
      "Layer 24 done\n",
      "Layer 25 done\n",
      "Layer 26 done\n",
      "Layer 27 done\n",
      "Layer 28 done\n",
      "Layer 29 done\n",
      "Layer 30 done\n"
     ]
    }
   ],
   "source": [
    "#visualise all layers for a randomly generated image\n",
    "op_random_images2 = []\n",
    "layer2 = []\n",
    "random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "for i in range(len(model.features)):\n",
    "    cnn_random_visualization.selected_layer = i\n",
    "    output_image = cnn_random_visualization.visualise_layer_with_hooks(random_image)\n",
    "    op_random_images2.extend(output_image)\n",
    "    layer2.append(\"layer\"+str(i))\n",
    "    print(\"Layer\", i, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipyplot.plot_images(op_random_images2, max_images=i, labels=layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "#display the image\n",
    "plt.imshow(random_image)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab1ea1bbc64a25a735cdd83804af072055d29f17491929b49555a1cdb29e02e6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
